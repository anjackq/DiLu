{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-29T13:10:49.283765Z",
     "start_time": "2026-01-29T13:10:49.275047Z"
    }
   },
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from rich import print\n",
    "from IPython.display import HTML, display, Video\n",
    "\n",
    "# Gym and Highway-env\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "\n",
    "# DiLu Imports (Ensure these are in your path)\n",
    "from dilu.scenario.envScenario import EnvScenario\n",
    "from dilu.driver_agent.driverAgent import DriverAgent\n",
    "from dilu.driver_agent.vectorStore import DrivingMemory\n",
    "from dilu.driver_agent.reflectionAgent import ReflectionAgent\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- Configuration Dictionary (Replacing config.yaml) ---\n",
    "config = {\n",
    "    # API Configuration (Fill in your actual keys)\n",
    "    #'OPENAI_API_TYPE': 'openai',  # or 'azure'\n",
    "    #'OPENAI_KEY': 'sk-proj-YOUR_OPENAI_KEY_HERE',\n",
    "    #'OPENAI_CHAT_MODEL': 'gpt-4-turbo',\n",
    "    'OPENAI_API_TYPE': 'ollama',  # or 'ollama' for local small models\n",
    "    'OPENAI_KEY': 'ollama',\n",
    "    'OPENAI_CHAT_MODEL': 'qwen2.5:14b', # use a model pulled by ollama (e.g. 'qwen2.5:14b' or 'llama3.1')\n",
    "\n",
    "    # Azure specific (leave empty if using openai)\n",
    "    'AZURE_API_VERSION': '',\n",
    "    'AZURE_API_BASE': '',\n",
    "    'AZURE_API_KEY': '',\n",
    "    'AZURE_CHAT_DEPLOY_NAME': '',\n",
    "    'AZURE_EMBED_DEPLOY_NAME': '',\n",
    "\n",
    "    # Simulation Settings\n",
    "    'vehicle_count': 50,\n",
    "    'other_vehicle_type': 'highway_env.vehicle.behavior.IDMVehicle',\n",
    "    'simulation_duration': 40, # Steps per episode\n",
    "    'vehicles_density': 2,\n",
    "    'episodes_num': 1, # Number of episodes to run in this cell\n",
    "\n",
    "    # DiLu Specific\n",
    "    'reflection_module': True,\n",
    "    'memory_path': './memory_db', # Local path for vector store\n",
    "    'few_shot_num': 3,\n",
    "    'result_folder': './results'\n",
    "}\n",
    "\n",
    "# --- Environment Setup Function ---\n",
    "def setup_env_vars(config):\n",
    "    if config['OPENAI_API_TYPE'] == 'azure':\n",
    "        os.environ[\"OPENAI_API_TYPE\"] = config['OPENAI_API_TYPE']\n",
    "        os.environ[\"OPENAI_API_VERSION\"] = config['AZURE_API_VERSION']\n",
    "        os.environ[\"OPENAI_API_BASE\"] = config['AZURE_API_BASE']\n",
    "        os.environ[\"OPENAI_API_KEY\"] = config['AZURE_API_KEY']\n",
    "        os.environ[\"AZURE_CHAT_DEPLOY_NAME\"] = config['AZURE_CHAT_DEPLOY_NAME']\n",
    "        os.environ[\"AZURE_EMBED_DEPLOY_NAME\"] = config['AZURE_EMBED_DEPLOY_NAME']\n",
    "    elif config['OPENAI_API_TYPE'] == 'openai':\n",
    "        os.environ[\"OPENAI_API_TYPE\"] = config['OPENAI_API_TYPE']\n",
    "        os.environ[\"OPENAI_API_KEY\"] = config['OPENAI_KEY']\n",
    "        os.environ[\"OPENAI_CHAT_MODEL\"] = config['OPENAI_CHAT_MODEL']\n",
    "\n",
    "    # Case 3: Ollama (NEW)\n",
    "    elif config['OPENAI_API_TYPE'] == 'ollama':\n",
    "        # We tell the system it's \"openai\" so libraries behave normally\n",
    "        os.environ[\"OPENAI_API_TYPE\"] = 'openai'\n",
    "\n",
    "        # Point to local host\n",
    "        os.environ[\"OPENAI_API_BASE\"] = \"http://localhost:11434/v1\"  # Used by LangChain/Old libs\n",
    "        os.environ[\"OPENAI_BASE_URL\"] = \"http://localhost:11434/v1\"  # Used by Newer OpenAI libs\n",
    "\n",
    "        # Dummy key and model\n",
    "        os.environ[\"OPENAI_API_KEY\"] = \"ollama\"\n",
    "        os.environ[\"OPENAI_CHAT_MODEL\"] = config['OPENAI_CHAT_MODEL']\n",
    "\n",
    "        print(f\"[bold yellow]Using Local Ollama Model: {config['OPENAI_CHAT_MODEL']}[/bold yellow]\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown OPENAI_API_TYPE, should be azure or openai\")\n",
    "\n",
    "def get_env_config(config):\n",
    "    return {\n",
    "        'highway-v0': {\n",
    "            \"observation\": {\n",
    "                \"type\": \"Kinematics\",\n",
    "                \"features\": [\"presence\", \"x\", \"y\", \"vx\", \"vy\"],\n",
    "                \"absolute\": True,\n",
    "                \"normalize\": False,\n",
    "                \"vehicles_count\": config[\"vehicle_count\"],\n",
    "                \"see_behind\": True,\n",
    "            },\n",
    "            \"action\": {\n",
    "                \"type\": \"DiscreteMetaAction\",\n",
    "                \"target_speeds\": np.linspace(5, 32, 9),\n",
    "            },\n",
    "            \"lanes_count\": 4,\n",
    "            \"other_vehicles_type\": config[\"other_vehicle_type\"],\n",
    "            \"duration\": config[\"simulation_duration\"],\n",
    "            \"vehicles_density\": config[\"vehicles_density\"],\n",
    "            \"show_trajectories\": True,\n",
    "            \"render_agent\": True,\n",
    "            \"scaling\": 5,\n",
    "            'initial_lane_id': None,\n",
    "            \"ego_spacing\": 4,\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Helper to display video in notebook\n",
    "def show_video(result_folder, prefix):\n",
    "    mp4list = glob.glob(f'{result_folder}/{prefix}*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = open(mp4, 'rb').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        display(HTML(data='''<video alt=\"test\" autoplay\n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")\n",
    "\n",
    "# Run Setup\n",
    "setup_env_vars(config)\n",
    "env_config = get_env_config(config)\n",
    "test_list_seed = [5838, 2421, 7294, 9650, 4176, 6382, 8765, 1348]\n",
    "\n",
    "if not os.path.exists(config[\"result_folder\"]):\n",
    "    os.makedirs(config[\"result_folder\"])\n",
    "\n",
    "print(f\"[bold green]Setup Complete.[/bold green] Memory Path: {config['memory_path']}\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1;33mUsing Local Ollama Model: qwen2.\u001B[0m\u001B[1;33m5:14b\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Using Local Ollama Model: qwen2.5:14b</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1;32mSetup Complete.\u001B[0m Memory Path: .\u001B[35m/\u001B[0m\u001B[95mmemory_db\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Setup Complete.</span> Memory Path: .<span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">memory_db</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T13:10:52.672085Z",
     "start_time": "2026-01-29T13:10:52.643182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 2: Initialize Agents and Memory\n",
    "# Only run this once to load the DB\n",
    "REFLECTION = config[\"reflection_module\"]\n",
    "memory_path = config[\"memory_path\"]\n",
    "few_shot_num = config[\"few_shot_num\"]\n",
    "\n",
    "# Initialize Memory\n",
    "agent_memory = DrivingMemory(db_path=memory_path)\n",
    "\n",
    "if REFLECTION:\n",
    "    updated_memory = DrivingMemory(db_path=memory_path + \"_updated\")\n",
    "    try:\n",
    "        updated_memory.combineMemory(agent_memory)\n",
    "        print(\"[cyan]Memory combined successfully.[/cyan]\")\n",
    "    except Exception as e:\n",
    "        print(f\"[yellow]Note on memory combination:[/yellow] {e}\")\n",
    "\n",
    "print(f\"[bold]Agents initialized.[/bold] Reflection mode: {REFLECTION}\")"
   ],
   "id": "d6dc4b60680c3df1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event client_start: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event client_start: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Loaded  ./memory_db  Memory, Now the database has  0  items.==========\n",
      "==========Loaded  ./memory_db_updated  Memory, Now the database has  0  items.==========\n",
      "Merge complete. Now the database has  0  items.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[36mMemory combined successfully.\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Memory combined successfully.</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mAgents initialized.\u001B[0m Reflection mode: \u001B[3;92mTrue\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Agents initialized.</span> Reflection mode: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-29T13:11:04.060767Z",
     "start_time": "2026-01-29T13:10:54.736078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell 3: Main Simulation Loop\n",
    "episode = 0\n",
    "result_folder = config[\"result_folder\"]\n",
    "lanes_count = env_config['highway-v0']['lanes_count']\n",
    "\n",
    "# Logging start\n",
    "with open(result_folder + \"/\" + 'log.txt', 'a') as f:\n",
    "    f.write(f\"Batch Start | memory_path {memory_path} | few_shot_num: {few_shot_num} \\n\")\n",
    "\n",
    "while episode < config[\"episodes_num\"]:\n",
    "    print(f\"\\n[bold magenta]=== Starting Episode {episode} ===[/bold magenta]\")\n",
    "\n",
    "    # 1. Setup Highway Env\n",
    "    envType = 'highway-v0'\n",
    "    env = gym.make(envType, render_mode=\"rgb_array\")\n",
    "    env.configure(env_config[envType])\n",
    "\n",
    "    result_prefix = f\"highway_qwen2.5_14b_ep{episode}\"\n",
    "\n",
    "    # Video Wrapper\n",
    "    env = RecordVideo(env, result_folder, name_prefix=result_prefix)\n",
    "    env.unwrapped.set_record_video_wrapper(env)\n",
    "\n",
    "    seed = random.choice(test_list_seed)\n",
    "    obs, info = env.reset(seed=seed)\n",
    "\n",
    "    # 2. Scenario and Agents\n",
    "    database_path = f\"{result_folder}/{result_prefix}.db\"\n",
    "    sce = EnvScenario(env, envType, seed, database_path)\n",
    "    DA = DriverAgent(sce, verbose=True) # Set verbose=False to reduce notebook clutter\n",
    "    if REFLECTION:\n",
    "        RA = ReflectionAgent(verbose=True)\n",
    "\n",
    "    # 3. Simulation Loop\n",
    "    response = \"Not available\"\n",
    "    action = \"Not available\"\n",
    "    docs = []\n",
    "    collision_frame = -1\n",
    "    already_decision_steps = 0\n",
    "\n",
    "    try:\n",
    "        for i in range(0, config[\"simulation_duration\"]):\n",
    "            obs = np.array(obs, dtype=float)\n",
    "\n",
    "            # Retrieve Memory\n",
    "            fewshot_results = []\n",
    "            if few_shot_num > 0:\n",
    "                fewshot_results = agent_memory.retriveMemory(sce, i, few_shot_num)\n",
    "                print(f\"Step {i}: Found {len(fewshot_results)} similar memories.\")\n",
    "\n",
    "            fewshot_messages = [res[\"human_question\"] for res in fewshot_results]\n",
    "            fewshot_answers = [res[\"LLM_response\"] for res in fewshot_results]\n",
    "\n",
    "            # Scenario Description\n",
    "            sce_descrip = sce.describe(i)\n",
    "            avail_action = sce.availableActionsDescription()\n",
    "\n",
    "            # Decision\n",
    "            action, response, human_question, fewshot_answer = DA.few_shot_decision(\n",
    "                scenario_description=sce_descrip,\n",
    "                available_actions=avail_action,\n",
    "                previous_decisions=action,\n",
    "                fewshot_messages=fewshot_messages,\n",
    "                driving_intensions=\"Drive safely and avoid collisons\",\n",
    "                fewshot_answers=fewshot_answers,\n",
    "            )\n",
    "\n",
    "            # Store Doc\n",
    "            docs.append({\n",
    "                \"sce_descrip\": sce_descrip,\n",
    "                \"human_question\": human_question,\n",
    "                \"response\": response,\n",
    "                \"action\": action,\n",
    "                \"sce\": copy.deepcopy(sce)\n",
    "            })\n",
    "\n",
    "            # Step Environment\n",
    "            obs, reward, done, info, _ = env.step(action)\n",
    "            already_decision_steps += 1\n",
    "\n",
    "            # Commit Prompt & Update Video\n",
    "            sce.promptsCommit(i, None, done, human_question, fewshot_answer, response)\n",
    "            env.video_recorder.capture_frame()\n",
    "\n",
    "            if done:\n",
    "                print(f\"[bold red]CRASH / DONE at step {i}[/bold red]\")\n",
    "                collision_frame = i\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[red]Error during simulation:[/red] {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "    finally:\n",
    "        env.close()\n",
    "\n",
    "        # Log results\n",
    "        with open(result_folder + \"/\" + 'log.txt', 'a') as f:\n",
    "            f.write(f\"Episode {episode} | Seed {seed} | Steps: {already_decision_steps}\\n\")\n",
    "\n",
    "        # 4. Reflection Logic (Interactive Input)\n",
    "        if REFLECTION:\n",
    "            print(\"[yellow]--- Reflection Phase ---[/yellow]\")\n",
    "            if collision_frame != -1:\n",
    "                # Crash Case\n",
    "                print(f\"Analyzing crash at frame {collision_frame}\")\n",
    "                for i in range(collision_frame, -1, -1):\n",
    "                    # Simple heuristic: look for steps where we didn't decelerate (action 4 usually)\n",
    "                    if docs[i][\"action\"] != 4:\n",
    "                        print(f\"Found suspicious action at step {i}\")\n",
    "                        corrected_response = RA.reflection(docs[i][\"human_question\"], docs[i][\"response\"])\n",
    "                        print(f\"[bold]Suggested Correction:[/bold] {corrected_response}\")\n",
    "\n",
    "                        # Notebook Input\n",
    "                        choice = input(\"Add this correction to memory? (Y/N): \").strip().upper()\n",
    "                        if choice == 'Y':\n",
    "                            updated_memory.addMemory(\n",
    "                                docs[i][\"sce_descrip\"], docs[i][\"human_question\"],\n",
    "                                corrected_response, docs[i][\"action\"],\n",
    "                                docs[i][\"sce\"], comments=\"mistake-correction\"\n",
    "                            )\n",
    "                            print(\"[green]Memory updated.[/green]\")\n",
    "                        break\n",
    "            else:\n",
    "                # Success Case\n",
    "                print(f\"Episode successful. {len(docs)//5} potential memories to add.\")\n",
    "                choice = input(\"Add successful memories? (Y/N): \").strip().upper()\n",
    "                if choice == 'Y':\n",
    "                    cnt = 0\n",
    "                    for i in range(0, len(docs)):\n",
    "                        if i % 5 == 1: # Subsample memories\n",
    "                            updated_memory.addMemory(\n",
    "                                docs[i][\"sce_descrip\"], docs[i][\"human_question\"],\n",
    "                                docs[i][\"response\"], docs[i][\"action\"],\n",
    "                                docs[i][\"sce\"], comments=\"no-mistake-direct\"\n",
    "                            )\n",
    "                            cnt +=1\n",
    "                    print(f\"[green]Added {cnt} new memories.[/green]\")\n",
    "\n",
    "    # Show the video of the run\n",
    "    print(f\"Episode {episode} Video:\")\n",
    "    show_video(result_folder, result_prefix)\n",
    "\n",
    "    episode += 1"
   ],
   "id": "acc70e1f7c23e418",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001B[1;35m=== Starting Episode \u001B[0m\u001B[1;35m0\u001B[0m\u001B[1;35m ===\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">=== Starting Episode </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">0</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> ===</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Use OpenAI API\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Use OpenAI API\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[31mCautious: Reflection mode uses OpenAI GPT-\u001B[0m\u001B[1;31m4\u001B[0m\u001B[31m, may cost a lot of money!\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Cautious: Reflection mode uses OpenAI GPT-</span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">4</span><span style=\"color: #800000; text-decoration-color: #800000\">, may cost a lot of money!</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[31mError during simulation:\u001B[0m invalid input type\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">Error during simulation:</span> invalid input type\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\WiCon\\AppData\\Local\\Temp\\ipykernel_51592\\4127527668.py\", line 48, in <module>\n",
      "    fewshot_results = agent_memory.retriveMemory(sce, i, few_shot_num)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\Desktop\\DiLu\\dilu\\driver_agent\\vectorStore.py\", line 43, in retriveMemory\n",
      "    similarity_results = self.scenario_memory.similarity_search_with_score(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py\", line 432, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\langchain\\embeddings\\openai.py\", line 578, in embed_query\n",
      "    return self.embed_documents([text])[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\langchain\\embeddings\\openai.py\", line 549, in embed_documents\n",
      "    return self._get_len_safe_embeddings(texts, engine=engine)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\langchain\\embeddings\\openai.py\", line 425, in _get_len_safe_embeddings\n",
      "    response = embed_with_retry(\n",
      "               ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\langchain\\embeddings\\openai.py\", line 114, in embed_with_retry\n",
      "    return _embed_with_retry(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\tenacity\\__init__.py\", line 336, in wrapped_f\n",
      "    return copy(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\tenacity\\__init__.py\", line 475, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\tenacity\\__init__.py\", line 376, in iter\n",
      "    result = action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\tenacity\\__init__.py\", line 398, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\tenacity\\__init__.py\", line 478, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\langchain\\embeddings\\openai.py\", line 111, in _embed_with_retry\n",
      "    response = embeddings.client.create(**kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\openai\\api_resources\\embedding.py\", line 33, in create\n",
      "    response = super().create(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py\", line 155, in create\n",
      "    response, _, api_key = requestor.request(\n",
      "                           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\openai\\api_requestor.py\", line 299, in request\n",
      "    resp, got_stream = self._interpret_response(result, stream)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\openai\\api_requestor.py\", line 710, in _interpret_response\n",
      "    self._interpret_response_line(\n",
      "  File \"C:\\Users\\WiCon\\anaconda3\\envs\\DiLu\\Lib\\site-packages\\openai\\api_requestor.py\", line 775, in _interpret_response_line\n",
      "    raise self.handle_error_response(\n",
      "openai.error.InvalidRequestError: invalid input type\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building video C:\\Users\\WiCon\\Desktop\\DiLu\\examples\\results\\highway_qwen2.5_14b_ep0-episode-0.mp4.\n",
      "MoviePy - Writing video C:\\Users\\WiCon\\Desktop\\DiLu\\examples\\results\\highway_qwen2.5_14b_ep0-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready C:\\Users\\WiCon\\Desktop\\DiLu\\examples\\results\\highway_qwen2.5_14b_ep0-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[33m--- Reflection Phase ---\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">--- Reflection Phase ---</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Episode successful. \u001B[1;36m0\u001B[0m potential memories to add.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode successful. <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> potential memories to add.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[32mAdded \u001B[0m\u001B[1;32m0\u001B[0m\u001B[32m new memories.\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Added </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span><span style=\"color: #008000; text-decoration-color: #008000\"> new memories.</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Episode \u001B[1;36m0\u001B[0m Video:\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Episode <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> Video:\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<video alt=\"test\" autoplay\n",
       "                loop controls style=\"height: 400px;\">\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1d563c02b650e966"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
